[
  {
    "path": "posts/2024-03-03-introduction-to-selenium-with-twitter-data/",
    "title": "Introduction to Selenium with Twitter Data",
    "description": "Let's scrape Twitter data using Selenium",
    "author": [
      {
        "name": "Guada Gonzalez",
        "url": "https://guadagonzalez.com/"
      }
    ],
    "date": "2024-03-03",
    "categories": [],
    "contents": "\r\nScraping means ‚Äòto gather, collect‚Äô and it‚Äôs a very important tool that we social scientists have to acquire innovative and valuable information that not everyone has access to.\r\nIn general, we scrape web pages using two methods. One is based on HTML code, which is simpler, and the other is based on Javascript, which is a bit more complex. For scraping HTML, there are very good tutorials like this, this, and this, using packages like Beautifulsoup in Python and rvest in R. In this case, we will use Selenium in Python to obtain the number of followers and followings that legislators have in Argentina.\r\nIt‚Äôs not necessary to know Javascript to use Selenium, but it is necessary to be able to identify, in this case, classes within the source codes of the websites. That is, to understand a little bit of HTML and CSS.\r\nDisclaimer to expand the issue:\r\nIn HTML, elements have an ID and a class. An ‚ÄúID‚Äù is ___ and a class is ‚Äú__‚Äú. In this case, IDs are indicated with‚Äù#‚Äù in front and classes with a dot ‚Äú.‚Äù in front.\r\nDownloading the number of followers and followings of legislators. For this, we will first try with a single account and then incorporate it into a loop.\r\nFor this, the following packages are necessary:\r\n\r\nimport random\r\nimport BeautifulSoup\r\nfrom time import sleep\r\nfrom selenium import webdriver\r\nfrom selenium.webdriver.common.by import By\r\nfrom selenium.webdriver.support.ui import WebDriverWait\r\nfrom selenium.webdriver.support import expected_conditions as EC\r\nfrom selenium.webdriver.common.keys import Keys\r\nfrom selenium.webdriver.common.action_chains import ActionChains\r\nimport re\r\nimport json\r\n\r\nThirdly, we call the driver. What is this?_\r\n\r\nWhen we run it automatically, we‚Äôll see that an internet tab opens:\r\n[Image]\r\nThen we specify the URL we want to scrape together with the get() function that will send us to the web. In this case, for example, we want to scrape my Twitter account.\r\n\r\ndriver_ = webdriver.Chrome()\r\n\r\nurl = 'https://twitter.com/guadag12'\r\ndriver_.get(url)\r\nsleep(2)  # Adding sleep to ensure page loads. Consider using WebDriverWait for better practice.\r\n\r\nWebDriverWait(driver_, 10).until(\r\n    EC.presence_of_all_elements_located((By.CSS_SELECTOR, \".css-1rynq56.r-bcqeeo.r-qvutc0.r-37j5jr.r-a023e6.r-rjixqe.r-16dba41.r-1loqt21\"))\r\n)\r\n\r\nOnce we run it, we need to see how it opens the new tab.\r\n! Warning: It‚Äôs always good practice to give seconds of rest between visiting a website and scraping it, so we give the browser time to load and likewise, we don‚Äôt overload the website. Using the ‚Äúsleep()‚Äù function implies being responsible with scraping use because ultimately, it‚Äôs a tool that forces the extraction of information in a context where we don‚Äôt necessarily ask the company for information. So let‚Äôs be responsible and respectful and put a sleep occasionally.\r\nThen we search on the web for the id/class of the element we want to scrape. In this case, as we want the number of followers and followings, we use this:\r\nWe use the ‚Äúfind_elements()‚Äù function and ask it to bring us an element determined by a CSS feature such as class, and we specify the class as a string:\r\n[Image]\r\nWhat it will automatically do is bring that data, and then we ask it to print it, and it will return something like this.\r\n\r\nh4_elements = driver_.find_elements(By.CSS_SELECTOR, \".css-1rynq56.r-bcqeeo.r-qvutc0.r-37j5jr.r-a023e6.r-rjixqe.r-16dba41.r-1loqt21\")\r\ntype_projects = [element.text.strip() for element in h4_elements]\r\nprint(type_projects)\r\n\r\nparsed_numbers = [parse_number(num) for num in type_projects]\r\n\r\nfollowing = parsed_numbers[0]\r\nfollowers = parsed_numbers[1]\r\n\r\nuser_data_new = {\r\n    \"User\": url,\r\n    \"Following\": following,\r\n    \"Followers\": followers\r\n}\r\n\r\nOnce we finish, we close the session:\r\n\r\ndriver_.quit()\r\n\r\nLOOP with Twitter accounts of Argentine legislators:\r\nWhat if we want to extract data from a large number of accounts? We need to\r\nBring the dataset with the accounts of Argentine legislators\r\nCreate an empty list to fill in later and\r\nPerform a for loop where in each iteration the information of each user is obtained\r\nBut before showing how the code would look like to do this, it‚Äôs important to know first that there are cases where legislators appear with ‚Äú1.1k followers‚Äù or ‚Äú1.3M followers‚Äù (millions). What we want to do is replace those ‚Äúk‚Äù or ‚ÄúM‚Äù with the corresponding number of zeros. In this regard, this function is created to be used within the loop:\r\n\r\n\r\n\r\nNow, this is how the final loop would look like:\r\nAnd in this file, you can observe the final data:\r\nFor example, if we want to see which block has the highest number of followers on Twitter according to the number of block members, we see that:\r\n\r\n\r\n\r\nThis has been everything. Thank you for getting here and reading to the end,\r\nLeave comments for any questions,\r\nGuada\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2024-03-03T15:15:21-03:00",
    "input_file": "introduction-to-selenium-with-twitter-data.knit.md"
  },
  {
    "path": "posts/2023-05-03-politicxs-en-twitter-again-online/",
    "title": "Analyzing political candidates with politicxsentwitteR!",
    "description": "Discover the revamped PoliticxsentwitteR website! Analyze political tweets, uncover engagement, words, emojis, and retweet dynamics in Argentina. Download data for deeper insights. Explore it! üöÄüíª",
    "author": [
      {
        "name": "Guadalupe Gonzalez",
        "url": "https://guadagonzalez.com/"
      }
    ],
    "date": "2023-05-09",
    "categories": [
      "R",
      "STATS",
      "Network Analysis",
      "politicxsentwitteR"
    ],
    "contents": "\r\nFrom the Network Observatory together with Democracia en Red and the National Democratic Institute we are excited to announce the relaunch of our PoliticxsentwitteR website üê¶üìä, now with updated data up to June 2022! üéâ\r\n\r\nüì¢ The app that I have the honor to develop analyzes tweets from politicians in Argentina  and provides insights into their engagement, the words and emojis that they use, and also who retweets who. It also provides the opportunity to free download the tweets so they can be analyzed and give users a more comprehensive view of political discourse on Twitter.\r\nWe hope that this update will provide valuable insights into political discourse in Argentina, and we encourage you to give it a try ü§©. You can access the app by visiting this linküîó.\r\n\r\n\r\n\r\n\r\nAnother important announcement is that politicxsintwitteR R package üì¶ is also available to make the data as much accessible as possible. In this post I showed you what opportunities the package bring! Also, you can check this social network tutorial that I present thanks to R ladies Buenos Aires using politicxsintwitteR.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-05-03-politicxs-en-twitter-again-online/logo.png",
    "last_modified": "2023-05-10T17:06:49+01:00",
    "input_file": "politicxs-en-twitter-again-online.knit.md",
    "preview_width": 1040,
    "preview_height": 1204
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to my new blog!",
    "description": "I hope you enjoy reading what I have to say!",
    "author": [
      {
        "name": "Guadalupe Gonzalez",
        "url": "https://github.com/guadag12"
      }
    ],
    "date": "2023-04-05",
    "categories": [],
    "contents": "\nWelcome to my blog! üëã I‚Äôm excited to share our passion for quantitative methods, political science,\nand public opinion research with you üîç. My goal is to provide a space where researchers, academics,\nand students can learn and discuss the developments in these fields.\nOne of the core aspects of my blog is the commitment to reproducibility ‚ôªÔ∏è. I believe that research should be\ntransparent and accessible to everyone, and one way to achieve this is by ensuring that our analyses can be easily replicated. That‚Äôs why I will be offering step-by-step tutorials on how to reproduce published studies using R .\nI will cover a broad range of topics, including statistical analysis, social network, public opinion analysis, text mining, deep learning, and much more üìä. Whether you‚Äôre an experienced researcher or just starting out, we hope that our blog will provide you with valuable insights and practical tips for your work.\nI encourage you to engage through comments and discussions üì•. My blog is a collaborative space where we can learn from each other and exchange ideas. Feel free to DM me about feedback, question or even new ideas suggestions for future blog posts!\nThank you for joining me on this journey üôè. I am excited to share my expertise and learn from you!\nBest ‚ù§Ô∏è,\nGuada\n\n\n\n",
    "preview": {},
    "last_modified": "2023-04-21T14:34:07+01:00",
    "input_file": {}
  }
]
